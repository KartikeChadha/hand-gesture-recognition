{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mediapipe in /home/kartike/.local/lib/python3.8/site-packages (0.9.2.1)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /home/kartike/.local/lib/python3.8/site-packages (from mediapipe) (23.3.3)\n",
      "Requirement already satisfied: opencv-contrib-python in /home/kartike/.local/lib/python3.8/site-packages (from mediapipe) (4.7.0.72)\n",
      "Requirement already satisfied: attrs>=19.1.0 in /home/kartike/.local/lib/python3.8/site-packages (from mediapipe) (22.2.0)\n",
      "Requirement already satisfied: numpy in /home/kartike/.local/lib/python3.8/site-packages (from mediapipe) (1.23.5)\n",
      "Requirement already satisfied: protobuf<4,>=3.11 in /home/kartike/.local/lib/python3.8/site-packages (from mediapipe) (3.20.3)\n",
      "Requirement already satisfied: matplotlib in /home/kartike/.local/lib/python3.8/site-packages (from mediapipe) (3.7.1)\n",
      "Requirement already satisfied: absl-py in /home/kartike/.local/lib/python3.8/site-packages (from mediapipe) (1.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/kartike/.local/lib/python3.8/site-packages (from matplotlib->mediapipe) (3.0.9)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/lib/python3/dist-packages (from matplotlib->mediapipe) (7.0.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/kartike/.local/lib/python3.8/site-packages (from matplotlib->mediapipe) (23.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/kartike/.local/lib/python3.8/site-packages (from matplotlib->mediapipe) (1.0.7)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/kartike/.local/lib/python3.8/site-packages (from matplotlib->mediapipe) (4.39.3)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0; python_version < \"3.10\" in /home/kartike/.local/lib/python3.8/site-packages (from matplotlib->mediapipe) (5.12.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/kartike/.local/lib/python3.8/site-packages (from matplotlib->mediapipe) (1.4.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/kartike/.local/lib/python3.8/site-packages (from matplotlib->mediapipe) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/kartike/.local/lib/python3.8/site-packages (from matplotlib->mediapipe) (0.11.0)\n",
      "Requirement already satisfied: zipp>=3.1.0; python_version < \"3.10\" in /home/kartike/.local/lib/python3.8/site-packages (from importlib-resources>=3.2.0; python_version < \"3.10\"->matplotlib->mediapipe) (3.15.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install mediap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 各パス指定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'model/keypoint_classifier/keypoints.csv'\n",
    "model_save_path = 'model/keypoint_classifier/keypoint_classifier.hdf5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分類数設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 学習データ読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dataset = np.loadtxt(dataset, delimiter=',', dtype='float32', usecols=list(range(1, (21 * 2) + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dataset = np.loadtxt(dataset, delimiter=',', dtype='int32', usecols=(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_dataset, y_dataset, train_size=0.75, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モデル構築"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input((21 * 2, )),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(20, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.4),\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dropout_16 (Dropout)        (None, 42)                0         \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 20)                860       \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 20)                0         \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 10)                210       \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 5)                 55        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,125\n",
      "Trainable params: 1,125\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()  # tf.keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルチェックポイントのコールバック\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    model_save_path, verbose=1, save_weights_only=False)\n",
    "# 早期打ち切り用コールバック\n",
    "es_callback = tf.keras.callbacks.EarlyStopping(patience=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルコンパイル\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モデル訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "27/35 [======================>.......] - ETA: 0s - loss: 1.4279 - accuracy: 0.4074\n",
      "Epoch 1: saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "35/35 [==============================] - 3s 20ms/step - loss: 1.3934 - accuracy: 0.4345 - val_loss: 1.1242 - val_accuracy: 0.5606\n",
      "Epoch 2/1000\n",
      "27/35 [======================>.......] - ETA: 0s - loss: 1.1723 - accuracy: 0.5376\n",
      "Epoch 2: saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 1.1635 - accuracy: 0.5342 - val_loss: 0.9670 - val_accuracy: 0.5544\n",
      "Epoch 3/1000\n",
      "28/35 [=======================>......] - ETA: 0s - loss: 1.0555 - accuracy: 0.5421\n",
      "Epoch 3: saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 1.0454 - accuracy: 0.5443 - val_loss: 0.8625 - val_accuracy: 0.5544\n",
      "Epoch 4/1000\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.9669 - accuracy: 0.5516\n",
      "Epoch 4: saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 0.9669 - accuracy: 0.5516 - val_loss: 0.7822 - val_accuracy: 0.5551\n",
      "Epoch 5/1000\n",
      "32/35 [==========================>...] - ETA: 0s - loss: 0.9032 - accuracy: 0.5808\n",
      "Epoch 5: saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 0.9006 - accuracy: 0.5812 - val_loss: 0.7113 - val_accuracy: 0.5619\n",
      "Epoch 6/1000\n",
      "33/35 [===========================>..] - ETA: 0s - loss: 0.8379 - accuracy: 0.6217\n",
      "Epoch 6: saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 0.8346 - accuracy: 0.6255 - val_loss: 0.6369 - val_accuracy: 0.6585\n",
      "Epoch 7/1000\n",
      "27/35 [======================>.......] - ETA: 0s - loss: 0.7959 - accuracy: 0.6641\n",
      "Epoch 7: saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 0.7904 - accuracy: 0.6670 - val_loss: 0.5640 - val_accuracy: 0.7878\n",
      "Epoch 8/1000\n",
      "30/35 [========================>.....] - ETA: 0s - loss: 0.7545 - accuracy: 0.6805\n",
      "Epoch 8: saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 0.7494 - accuracy: 0.6835 - val_loss: 0.4984 - val_accuracy: 0.8193\n",
      "Epoch 9/1000\n",
      "27/35 [======================>.......] - ETA: 0s - loss: 0.6802 - accuracy: 0.7245\n",
      "Epoch 9: saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 0.6814 - accuracy: 0.7202 - val_loss: 0.4316 - val_accuracy: 0.8056\n",
      "Epoch 10/1000\n",
      "30/35 [========================>.....] - ETA: 0s - loss: 0.6551 - accuracy: 0.7365\n",
      "Epoch 10: saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 0.6576 - accuracy: 0.7355 - val_loss: 0.3794 - val_accuracy: 0.8700\n",
      "Epoch 11/1000\n",
      "29/35 [=======================>......] - ETA: 0s - loss: 0.5967 - accuracy: 0.7508\n",
      "Epoch 11: saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 0.5992 - accuracy: 0.7533 - val_loss: 0.3334 - val_accuracy: 0.9103\n",
      "Epoch 12/1000\n",
      "34/35 [============================>.] - ETA: 0s - loss: 0.5722 - accuracy: 0.7705\n",
      "Epoch 12: saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 0.5739 - accuracy: 0.7695 - val_loss: 0.3084 - val_accuracy: 0.8768\n",
      "Epoch 13/1000\n",
      "33/35 [===========================>..] - ETA: 0s - loss: 0.5547 - accuracy: 0.7791\n",
      "Epoch 13: saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 0.5546 - accuracy: 0.7805 - val_loss: 0.2858 - val_accuracy: 0.9363\n",
      "Epoch 14/1000\n",
      "26/35 [=====================>........] - ETA: 0s - loss: 0.5569 - accuracy: 0.7812\n",
      "Epoch 14: saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 0.5549 - accuracy: 0.7814 - val_loss: 0.2676 - val_accuracy: 0.9363\n",
      "Epoch 15/1000\n",
      "31/35 [=========================>....] - ETA: 0s - loss: 0.5107 - accuracy: 0.7999\n",
      "Epoch 15: saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 0.5104 - accuracy: 0.8012 - val_loss: 0.2381 - val_accuracy: 0.9562\n",
      "Epoch 16/1000\n",
      "27/35 [======================>.......] - ETA: 0s - loss: 0.5199 - accuracy: 0.7905\n",
      "Epoch 16: saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 0.5152 - accuracy: 0.7951 - val_loss: 0.2315 - val_accuracy: 0.9446\n",
      "Epoch 17/1000\n",
      "27/35 [======================>.......] - ETA: 0s - loss: 0.5009 - accuracy: 0.8009\n",
      "Epoch 17: saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 0.5006 - accuracy: 0.8001 - val_loss: 0.2266 - val_accuracy: 0.9391\n",
      "Epoch 18/1000\n",
      "27/35 [======================>.......] - ETA: 0s - loss: 0.5001 - accuracy: 0.8070\n",
      "Epoch 18: saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 0.5019 - accuracy: 0.8063 - val_loss: 0.2182 - val_accuracy: 0.9493\n",
      "Epoch 19/1000\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.4886 - accuracy: 0.8081\n",
      "Epoch 19: saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 0.4886 - accuracy: 0.8081 - val_loss: 0.2104 - val_accuracy: 0.9507\n",
      "Epoch 20/1000\n",
      "29/35 [=======================>......] - ETA: 0s - loss: 0.4694 - accuracy: 0.8276\n",
      "Epoch 20: saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 0.4704 - accuracy: 0.8252 - val_loss: 0.1951 - val_accuracy: 0.9576\n",
      "Epoch 21/1000\n",
      "29/35 [=======================>......] - ETA: 0s - loss: 0.4661 - accuracy: 0.8281\n",
      "Epoch 21: saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 0.4761 - accuracy: 0.8229 - val_loss: 0.1953 - val_accuracy: 0.9528\n",
      "Epoch 22/1000\n",
      "32/35 [==========================>...] - ETA: 0s - loss: 0.4441 - accuracy: 0.8350\n",
      "Epoch 22: saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 0.4489 - accuracy: 0.8355 - val_loss: 0.1811 - val_accuracy: 0.9603\n",
      "Epoch 23/1000\n",
      "28/35 [=======================>......] - ETA: 0s - loss: 0.4533 - accuracy: 0.8315\n",
      "Epoch 23: saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 0.4534 - accuracy: 0.8307 - val_loss: 0.1714 - val_accuracy: 0.9651\n",
      "Epoch 24/1000\n",
      "29/35 [=======================>......] - ETA: 0s - loss: 0.4445 - accuracy: 0.8316\n",
      "Epoch 24: saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 0.4448 - accuracy: 0.8341 - val_loss: 0.1764 - val_accuracy: 0.9644\n",
      "Epoch 25/1000\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.4251 - accuracy: 0.8398\n",
      "Epoch 25: saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 0.4251 - accuracy: 0.8398 - val_loss: 0.1534 - val_accuracy: 0.9678\n",
      "Epoch 26/1000\n",
      "29/35 [=======================>......] - ETA: 0s - loss: 0.4348 - accuracy: 0.8359\n",
      "Epoch 26: saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 0.4327 - accuracy: 0.8348 - val_loss: 0.1573 - val_accuracy: 0.9665\n",
      "Epoch 27/1000\n",
      "33/35 [===========================>..] - ETA: 0s - loss: 0.4183 - accuracy: 0.8390\n",
      "Epoch 27: saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "35/35 [==============================] - 0s 14ms/step - loss: 0.4181 - accuracy: 0.8382 - val_loss: 0.1523 - val_accuracy: 0.9678\n",
      "Epoch 28/1000\n",
      "27/35 [======================>.......] - ETA: 0s - loss: 0.4181 - accuracy: 0.8443\n",
      "Epoch 28: saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 0.4220 - accuracy: 0.8446 - val_loss: 0.1536 - val_accuracy: 0.9665\n",
      "Epoch 29/1000\n",
      "32/35 [==========================>...] - ETA: 0s - loss: 0.4167 - accuracy: 0.8445\n",
      "Epoch 29: saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 0.4166 - accuracy: 0.8437 - val_loss: 0.1535 - val_accuracy: 0.9637\n",
      "Epoch 30/1000\n",
      "27/35 [======================>.......] - ETA: 0s - loss: 0.3997 - accuracy: 0.8530\n",
      "Epoch 30: saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 0.3956 - accuracy: 0.8551 - val_loss: 0.1358 - val_accuracy: 0.9719\n",
      "Epoch 31/1000\n",
      "30/35 [========================>.....] - ETA: 0s - loss: 0.3899 - accuracy: 0.8526\n",
      "Epoch 31: saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 0.3982 - accuracy: 0.8512 - val_loss: 0.1508 - val_accuracy: 0.9630\n",
      "Epoch 32/1000\n",
      "33/35 [===========================>..] - ETA: 0s - loss: 0.3947 - accuracy: 0.8539\n",
      "Epoch 32: saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 0.3975 - accuracy: 0.8537 - val_loss: 0.1366 - val_accuracy: 0.9692\n",
      "Epoch 33/1000\n",
      "28/35 [=======================>......] - ETA: 0s - loss: 0.3951 - accuracy: 0.8605\n",
      "Epoch 33: saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 0.4005 - accuracy: 0.8565 - val_loss: 0.1335 - val_accuracy: 0.9685\n",
      "Epoch 34/1000\n",
      "28/35 [=======================>......] - ETA: 0s - loss: 0.4131 - accuracy: 0.8438\n",
      "Epoch 34: saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 0.4123 - accuracy: 0.8441 - val_loss: 0.1462 - val_accuracy: 0.9665\n",
      "Epoch 35/1000\n",
      "25/35 [====================>.........] - ETA: 0s - loss: 0.3945 - accuracy: 0.8516\n",
      "Epoch 35: saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 0.3936 - accuracy: 0.8549 - val_loss: 0.1388 - val_accuracy: 0.9678\n",
      "Epoch 36/1000\n",
      "34/35 [============================>.] - ETA: 0s - loss: 0.3923 - accuracy: 0.8536\n",
      "Epoch 36: saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 0.3916 - accuracy: 0.8539 - val_loss: 0.1306 - val_accuracy: 0.9692\n",
      "Epoch 37/1000\n",
      "28/35 [=======================>......] - ETA: 0s - loss: 0.3775 - accuracy: 0.8583\n",
      "Epoch 37: saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 0.3741 - accuracy: 0.8601 - val_loss: 0.1260 - val_accuracy: 0.9699\n",
      "Epoch 38/1000\n",
      "32/35 [==========================>...] - ETA: 0s - loss: 0.3785 - accuracy: 0.8557\n",
      "Epoch 38: saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 0.3739 - accuracy: 0.8585 - val_loss: 0.1239 - val_accuracy: 0.9740\n",
      "Epoch 39/1000\n",
      "29/35 [=======================>......] - ETA: 0s - loss: 0.3708 - accuracy: 0.8602\n",
      "Epoch 39: saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 0.3664 - accuracy: 0.8626 - val_loss: 0.1211 - val_accuracy: 0.9719\n",
      "Epoch 40/1000\n",
      "30/35 [========================>.....] - ETA: 0s - loss: 0.3818 - accuracy: 0.8586\n",
      "Epoch 40: saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 0.3844 - accuracy: 0.8583 - val_loss: 0.1265 - val_accuracy: 0.9719\n",
      "Epoch 41/1000\n",
      "31/35 [=========================>....] - ETA: 0s - loss: 0.3707 - accuracy: 0.8606\n",
      "Epoch 41: saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 0.3724 - accuracy: 0.8599 - val_loss: 0.1316 - val_accuracy: 0.9678\n",
      "Epoch 42/1000\n",
      "33/35 [===========================>..] - ETA: 0s - loss: 0.3593 - accuracy: 0.8750\n",
      "Epoch 42: saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 0.3587 - accuracy: 0.8754 - val_loss: 0.1366 - val_accuracy: 0.9630\n",
      "Epoch 43/1000\n",
      "30/35 [========================>.....] - ETA: 0s - loss: 0.3617 - accuracy: 0.8664\n",
      "Epoch 43: saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 0.3600 - accuracy: 0.8667 - val_loss: 0.1151 - val_accuracy: 0.9733\n",
      "Epoch 44/1000\n",
      "31/35 [=========================>....] - ETA: 0s - loss: 0.3582 - accuracy: 0.8657\n",
      "Epoch 44: saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 0.3613 - accuracy: 0.8642 - val_loss: 0.1200 - val_accuracy: 0.9692\n",
      "Epoch 45/1000\n",
      "34/35 [============================>.] - ETA: 0s - loss: 0.3447 - accuracy: 0.8720\n",
      "Epoch 45: saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 0.3436 - accuracy: 0.8724 - val_loss: 0.1104 - val_accuracy: 0.9747\n",
      "Epoch 46/1000\n",
      "31/35 [=========================>....] - ETA: 0s - loss: 0.3508 - accuracy: 0.8715\n",
      "Epoch 46: saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 0.3458 - accuracy: 0.8745 - val_loss: 0.1116 - val_accuracy: 0.9767\n",
      "Epoch 47/1000\n",
      "32/35 [==========================>...] - ETA: 0s - loss: 0.3590 - accuracy: 0.8694\n",
      "Epoch 47: saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 0.3606 - accuracy: 0.8688 - val_loss: 0.1166 - val_accuracy: 0.9747\n",
      "Epoch 48/1000\n",
      "33/35 [===========================>..] - ETA: 0s - loss: 0.3511 - accuracy: 0.8724\n",
      "Epoch 48: saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 0.3485 - accuracy: 0.8733 - val_loss: 0.1181 - val_accuracy: 0.9719\n",
      "Epoch 49/1000\n",
      "33/35 [===========================>..] - ETA: 0s - loss: 0.3452 - accuracy: 0.8731\n",
      "Epoch 49: saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 0.3426 - accuracy: 0.8736 - val_loss: 0.1164 - val_accuracy: 0.9706\n",
      "Epoch 50/1000\n",
      "34/35 [============================>.] - ETA: 0s - loss: 0.3509 - accuracy: 0.8642\n",
      "Epoch 50: saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.3509 - accuracy: 0.8642 - val_loss: 0.1100 - val_accuracy: 0.9747\n",
      "Epoch 51/1000\n",
      "24/35 [===================>..........] - ETA: 0s - loss: 0.3418 - accuracy: 0.8711\n",
      "Epoch 51: saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.3405 - accuracy: 0.8717 - val_loss: 0.1196 - val_accuracy: 0.9685\n",
      "Epoch 52/1000\n",
      "32/35 [==========================>...] - ETA: 0s - loss: 0.3502 - accuracy: 0.8704\n",
      "Epoch 52: saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 0.3487 - accuracy: 0.8722 - val_loss: 0.1078 - val_accuracy: 0.9754\n",
      "Epoch 53/1000\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.3521 - accuracy: 0.8656\n",
      "Epoch 53: saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.3521 - accuracy: 0.8656 - val_loss: 0.1217 - val_accuracy: 0.9685\n",
      "Epoch 54/1000\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.3498 - accuracy: 0.8722\n",
      "Epoch 54: saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.3498 - accuracy: 0.8722 - val_loss: 0.1153 - val_accuracy: 0.9713\n",
      "Epoch 55/1000\n",
      "30/35 [========================>.....] - ETA: 0s - loss: 0.3317 - accuracy: 0.8802\n",
      "Epoch 55: saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 0.3279 - accuracy: 0.8813 - val_loss: 0.1123 - val_accuracy: 0.9706\n",
      "Epoch 56/1000\n",
      "29/35 [=======================>......] - ETA: 0s - loss: 0.3358 - accuracy: 0.8836\n",
      "Epoch 56: saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 0.3371 - accuracy: 0.8820 - val_loss: 0.1066 - val_accuracy: 0.9726\n",
      "Epoch 57/1000\n",
      "30/35 [========================>.....] - ETA: 0s - loss: 0.3339 - accuracy: 0.8768\n",
      "Epoch 57: saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 0.3301 - accuracy: 0.8765 - val_loss: 0.1124 - val_accuracy: 0.9685\n",
      "Epoch 58/1000\n",
      "25/35 [====================>.........] - ETA: 0s - loss: 0.3299 - accuracy: 0.8813\n",
      "Epoch 58: saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 0.3395 - accuracy: 0.8768 - val_loss: 0.1073 - val_accuracy: 0.9747\n",
      "Epoch 59/1000\n",
      "32/35 [==========================>...] - ETA: 0s - loss: 0.3102 - accuracy: 0.8848\n",
      "Epoch 59: saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 0.3120 - accuracy: 0.8850 - val_loss: 0.1028 - val_accuracy: 0.9740\n",
      "Epoch 60/1000\n",
      "31/35 [=========================>....] - ETA: 0s - loss: 0.3408 - accuracy: 0.8727\n",
      "Epoch 60: saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "35/35 [==============================] - 0s 13ms/step - loss: 0.3346 - accuracy: 0.8745 - val_loss: 0.0997 - val_accuracy: 0.9774\n",
      "Epoch 61/1000\n",
      "30/35 [========================>.....] - ETA: 0s - loss: 0.3327 - accuracy: 0.8747\n",
      "Epoch 61: saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 0.3363 - accuracy: 0.8749 - val_loss: 0.1028 - val_accuracy: 0.9767\n",
      "Epoch 62/1000\n",
      "29/35 [=======================>......] - ETA: 0s - loss: 0.3211 - accuracy: 0.8852\n",
      "Epoch 62: saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 0.3257 - accuracy: 0.8829 - val_loss: 0.1196 - val_accuracy: 0.9678\n",
      "Epoch 63/1000\n",
      "34/35 [============================>.] - ETA: 0s - loss: 0.2979 - accuracy: 0.8929\n",
      "Epoch 63: saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 0.2979 - accuracy: 0.8927 - val_loss: 0.1060 - val_accuracy: 0.9699\n",
      "Epoch 64/1000\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.3245 - accuracy: 0.8836\n",
      "Epoch 64: saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "35/35 [==============================] - 0s 14ms/step - loss: 0.3245 - accuracy: 0.8836 - val_loss: 0.1038 - val_accuracy: 0.9740\n",
      "Epoch 65/1000\n",
      "32/35 [==========================>...] - ETA: 0s - loss: 0.3066 - accuracy: 0.8904\n",
      "Epoch 65: saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 0.3084 - accuracy: 0.8884 - val_loss: 0.1017 - val_accuracy: 0.9733\n",
      "Epoch 66/1000\n",
      "30/35 [========================>.....] - ETA: 0s - loss: 0.3254 - accuracy: 0.8833\n",
      "Epoch 66: saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 0.3250 - accuracy: 0.8848 - val_loss: 0.1134 - val_accuracy: 0.9678\n",
      "Epoch 67/1000\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.3096 - accuracy: 0.8857\n",
      "Epoch 67: saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 0.3096 - accuracy: 0.8857 - val_loss: 0.1026 - val_accuracy: 0.9733\n",
      "Epoch 68/1000\n",
      "28/35 [=======================>......] - ETA: 0s - loss: 0.3025 - accuracy: 0.8870\n",
      "Epoch 68: saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 0.3037 - accuracy: 0.8857 - val_loss: 0.1065 - val_accuracy: 0.9706\n",
      "Epoch 69/1000\n",
      "29/35 [=======================>......] - ETA: 0s - loss: 0.3244 - accuracy: 0.8812\n",
      "Epoch 69: saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 0.3277 - accuracy: 0.8784 - val_loss: 0.1017 - val_accuracy: 0.9781\n",
      "Epoch 70/1000\n",
      "30/35 [========================>.....] - ETA: 0s - loss: 0.3091 - accuracy: 0.8859\n",
      "Epoch 70: saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 0.3063 - accuracy: 0.8861 - val_loss: 0.1085 - val_accuracy: 0.9699\n",
      "Epoch 71/1000\n",
      "28/35 [=======================>......] - ETA: 0s - loss: 0.3117 - accuracy: 0.8903\n",
      "Epoch 71: saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 0.3097 - accuracy: 0.8918 - val_loss: 0.1053 - val_accuracy: 0.9706\n",
      "Epoch 72/1000\n",
      "29/35 [=======================>......] - ETA: 0s - loss: 0.2969 - accuracy: 0.8925\n",
      "Epoch 72: saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 0.3031 - accuracy: 0.8891 - val_loss: 0.0842 - val_accuracy: 0.9815\n",
      "Epoch 73/1000\n",
      "31/35 [=========================>....] - ETA: 0s - loss: 0.3178 - accuracy: 0.8848\n",
      "Epoch 73: saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 0.3129 - accuracy: 0.8861 - val_loss: 0.1002 - val_accuracy: 0.9747\n",
      "Epoch 74/1000\n",
      "32/35 [==========================>...] - ETA: 0s - loss: 0.3044 - accuracy: 0.8879\n",
      "Epoch 74: saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 0.3057 - accuracy: 0.8882 - val_loss: 0.1054 - val_accuracy: 0.9719\n",
      "Epoch 75/1000\n",
      "31/35 [=========================>....] - ETA: 0s - loss: 0.3264 - accuracy: 0.8770\n",
      "Epoch 75: saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 0.3211 - accuracy: 0.8791 - val_loss: 0.1051 - val_accuracy: 0.9719\n",
      "Epoch 76/1000\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.3054 - accuracy: 0.8875\n",
      "Epoch 76: saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "35/35 [==============================] - 0s 11ms/step - loss: 0.3054 - accuracy: 0.8875 - val_loss: 0.0934 - val_accuracy: 0.9774\n",
      "Epoch 77/1000\n",
      "29/35 [=======================>......] - ETA: 0s - loss: 0.3006 - accuracy: 0.8882\n",
      "Epoch 77: saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 0.2983 - accuracy: 0.8880 - val_loss: 0.0982 - val_accuracy: 0.9774\n",
      "Epoch 78/1000\n",
      "33/35 [===========================>..] - ETA: 0s - loss: 0.3050 - accuracy: 0.8897\n",
      "Epoch 78: saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "35/35 [==============================] - 0s 12ms/step - loss: 0.3055 - accuracy: 0.8893 - val_loss: 0.1047 - val_accuracy: 0.9699\n",
      "Epoch 79/1000\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.2991 - accuracy: 0.8875\n",
      "Epoch 79: saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 0.2991 - accuracy: 0.8875 - val_loss: 0.0979 - val_accuracy: 0.9747\n",
      "Epoch 80/1000\n",
      "34/35 [============================>.] - ETA: 0s - loss: 0.3025 - accuracy: 0.8883\n",
      "Epoch 80: saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "35/35 [==============================] - 0s 10ms/step - loss: 0.3022 - accuracy: 0.8886 - val_loss: 0.0950 - val_accuracy: 0.9802\n",
      "Epoch 81/1000\n",
      "25/35 [====================>.........] - ETA: 0s - loss: 0.3171 - accuracy: 0.8819\n",
      "Epoch 81: saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.3198 - accuracy: 0.8811 - val_loss: 0.1164 - val_accuracy: 0.9671\n",
      "Epoch 82/1000\n",
      "27/35 [======================>.......] - ETA: 0s - loss: 0.2971 - accuracy: 0.8909\n",
      "Epoch 82: saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.3001 - accuracy: 0.8854 - val_loss: 0.1004 - val_accuracy: 0.9719\n",
      "Epoch 83/1000\n",
      "29/35 [=======================>......] - ETA: 0s - loss: 0.2942 - accuracy: 0.8893\n",
      "Epoch 83: saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 0.2895 - accuracy: 0.8914 - val_loss: 0.0922 - val_accuracy: 0.9767\n",
      "Epoch 84/1000\n",
      "26/35 [=====================>........] - ETA: 0s - loss: 0.3084 - accuracy: 0.8867\n",
      "Epoch 84: saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.3061 - accuracy: 0.8882 - val_loss: 0.1067 - val_accuracy: 0.9713\n",
      "Epoch 85/1000\n",
      "27/35 [======================>.......] - ETA: 0s - loss: 0.2797 - accuracy: 0.8941\n",
      "Epoch 85: saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.2894 - accuracy: 0.8902 - val_loss: 0.0932 - val_accuracy: 0.9781\n",
      "Epoch 86/1000\n",
      "34/35 [============================>.] - ETA: 0s - loss: 0.2992 - accuracy: 0.8895\n",
      "Epoch 86: saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.2997 - accuracy: 0.8893 - val_loss: 0.0959 - val_accuracy: 0.9781\n",
      "Epoch 87/1000\n",
      "27/35 [======================>.......] - ETA: 0s - loss: 0.2866 - accuracy: 0.8929\n",
      "Epoch 87: saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.2841 - accuracy: 0.8962 - val_loss: 0.0971 - val_accuracy: 0.9781\n",
      "Epoch 88/1000\n",
      "25/35 [====================>.........] - ETA: 0s - loss: 0.2867 - accuracy: 0.8913\n",
      "Epoch 88: saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.2854 - accuracy: 0.8907 - val_loss: 0.0913 - val_accuracy: 0.9726\n",
      "Epoch 89/1000\n",
      "30/35 [========================>.....] - ETA: 0s - loss: 0.2927 - accuracy: 0.8857\n",
      "Epoch 89: saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.2913 - accuracy: 0.8877 - val_loss: 0.0976 - val_accuracy: 0.9747\n",
      "Epoch 90/1000\n",
      "26/35 [=====================>........] - ETA: 0s - loss: 0.2867 - accuracy: 0.8942\n",
      "Epoch 90: saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.2895 - accuracy: 0.8907 - val_loss: 0.0939 - val_accuracy: 0.9781\n",
      "Epoch 91/1000\n",
      "25/35 [====================>.........] - ETA: 0s - loss: 0.2710 - accuracy: 0.8959\n",
      "Epoch 91: saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.2807 - accuracy: 0.8950 - val_loss: 0.0880 - val_accuracy: 0.9815\n",
      "Epoch 92/1000\n",
      "26/35 [=====================>........] - ETA: 0s - loss: 0.3041 - accuracy: 0.8846\n",
      "Epoch 92: saving model to model/keypoint_classifier/keypoint_classifier.hdf5\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.3044 - accuracy: 0.8827 - val_loss: 0.1044 - val_accuracy: 0.9747\n",
      "Epoch 92: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7c2f3e5430>"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=1000,\n",
    "    batch_size=128,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[cp_callback, es_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 5ms/step - loss: 0.1044 - accuracy: 0.9747\n"
     ]
    }
   ],
   "source": [
    "# モデル評価\n",
    "val_loss, val_acc = model.evaluate(X_test, y_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存したモデルのロード\n",
    "model = tf.keras.models.load_model(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 133ms/step\n",
      "[8.5312152e-10 4.3584243e-04 5.1814334e-07 9.7937876e-01 2.0184889e-02]\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# 推論テスト\n",
    "predict_result = model.predict(np.array([X_test[0]]))\n",
    "print(np.squeeze(predict_result))\n",
    "print(np.argmax(np.squeeze(predict_result)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       176\n",
      "           1       1.00      1.00      1.00       162\n",
      "           2       1.00      0.94      0.97       242\n",
      "           3       0.92      1.00      0.96       251\n",
      "           4       0.98      0.97      0.97       630\n",
      "\n",
      "    accuracy                           0.97      1461\n",
      "   macro avg       0.98      0.98      0.98      1461\n",
      "weighted avg       0.98      0.97      0.97      1461\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "def print_confusion_matrix(y_true, y_pred, report=True):\n",
    "    labels = sorted(list(set(y_true)))\n",
    "    cmx_data = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    \n",
    "    df_cmx = pd.DataFrame(cmx_data, index=labels, columns=labels)\n",
    " \n",
    "    fig, ax = plt.subplots(figsize=(7, 6))\n",
    "    sns.heatmap(df_cmx, annot=True, fmt='g' ,square=False)\n",
    "    ax.set_ylim(len(set(y_true)), 0)\n",
    "    plt.show()\n",
    "    \n",
    "    if report:\n",
    "        print('Classification Report')\n",
    "        print(classification_report(y_test, y_pred))\n",
    "\n",
    "Y_pred = model.predict(X_test)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "\n",
    "print_confusion_matrix(y_test, y_pred)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow-Lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 推論専用のモデルとして保存\n",
    "model.save(model_save_path, include_optimizer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-31 15:54:54.362978: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'input_9' with dtype float and shape [?,42]\n",
      "\t [[{{node input_9}}]]\n",
      "2023-03-31 15:54:54.671323: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,42]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-03-31 15:54:54.737163: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'input_9' with dtype float and shape [?,42]\n",
      "\t [[{{node input_9}}]]\n",
      "2023-03-31 15:54:54.885881: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,42]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-03-31 15:54:54.953229: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,20]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-03-31 15:54:55.043342: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,42]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-03-31 15:54:55.160767: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,42]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-03-31 15:54:55.286573: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,42]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-03-31 15:54:55.387121: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,20]\n",
      "\t [[{{node inputs}}]]\n",
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp3gxr7fad/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp3gxr7fad/assets\n",
      "2023-03-31 15:54:57.180180: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "2023-03-31 15:54:57.180283: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2023-03-31 15:54:57.181959: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /tmp/tmp3gxr7fad\n",
      "2023-03-31 15:54:57.183785: I tensorflow/cc/saved_model/reader.cc:89] Reading meta graph with tags { serve }\n",
      "2023-03-31 15:54:57.183840: I tensorflow/cc/saved_model/reader.cc:130] Reading SavedModel debug info (if present) from: /tmp/tmp3gxr7fad\n",
      "2023-03-31 15:54:57.194014: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
      "2023-03-31 15:54:57.282325: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: /tmp/tmp3gxr7fad\n",
      "2023-03-31 15:54:57.301693: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 119748 microseconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6652"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# モデルを変換(量子化)\n",
    "tflite_save_path = 'model/keypoint_classifier/keypoint_classifier.tflite'\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_quantized_model = converter.convert()\n",
    "\n",
    "open(tflite_save_path, 'wb').write(tflite_quantized_model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reasoning Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=tflite_save_path)\n",
    "interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 入出力テンソルを取得\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter.set_tensor(input_details[0]['index'], np.array([X_test[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 261 µs, sys: 19 µs, total: 280 µs\n",
      "Wall time: 241 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 推論実施\n",
    "interpreter.invoke()\n",
    "tflite_results = interpreter.get_tensor(output_details[0]['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7729778  0.16973573 0.05728643]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(np.squeeze(tflite_results))\n",
    "print(np.argmax(np.squeeze(tflite_results)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
